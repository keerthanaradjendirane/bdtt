{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a66c9ee8-0315-4865-8cc2-6929a7d576fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark==3.1.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (3.1.2)\n",
      "Requirement already satisfied: py4j==0.10.9 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pyspark==3.1.2) (0.10.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark==3.1.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8ddc0a1-72a5-493f-8db9-509841fa0f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Email: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- Avatar: string (nullable = true)\n",
      " |-- Avg Session Length: double (nullable = true)\n",
      " |-- Time on App: double (nullable = true)\n",
      " |-- Time on Website: double (nullable = true)\n",
      " |-- Length of Membership: double (nullable = true)\n",
      " |-- Yearly Amount Spent: double (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+---------+------------------+------------------+------------------+--------------------+-------------------+\n",
      "|               Email|             Address|   Avatar|Avg Session Length|       Time on App|   Time on Website|Length of Membership|Yearly Amount Spent|\n",
      "+--------------------+--------------------+---------+------------------+------------------+------------------+--------------------+-------------------+\n",
      "|mstephenson@ferna...|835 Frank TunnelW...|   Violet| 34.49726772511229| 12.65565114916675| 39.57766801952616|  4.0826206329529615|  587.9510539684005|\n",
      "|   hduke@hotmail.com|4547 Archer Commo...|DarkGreen| 31.92627202636016|11.109460728682564|37.268958868297744|    2.66403418213262|  392.2049334443264|\n",
      "|    pallen@yahoo.com|24645 Valerie Uni...|   Bisque|33.000914755642675|11.330278057777512|37.110597442120856|   4.104543202376424| 487.54750486747207|\n",
      "+--------------------+--------------------+---------+------------------+------------------+------------------+--------------------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE): 9.89641343699819\n",
      "R-Squared (R2): 0.9838160891408017\n",
      "+--------------------+-------------------+-----------------+\n",
      "|            features|Yearly Amount Spent|       prediction|\n",
      "+--------------------+-------------------+-----------------+\n",
      "|[30.8162006488763...|   266.086340948469|284.2218889332364|\n",
      "|[31.1280900496166...|  557.2526867470547|565.9725015606755|\n",
      "|[31.3123495994443...|  463.5914180279406|445.0943231988399|\n",
      "+--------------------+-------------------+-----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_PYTHON'] = r'C:\\Users\\asus\\anaconda3\\python.exe'\n",
    "os.environ['JAVA_HOME'] = r'C:\\Program Files\\Java\\jdk1.8.0_321'  # Update this to your Java installation path\n",
    "os.environ['SPARK_HOME'] = r'C:\\Users\\asus\\Documents\\BDT\\BigData\\BigData\\spark-3.1.2-bin-hadoop3.2'  # Update this to your Spark installation path\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"Linear Regression Model\").getOrCreate()\n",
    "\n",
    "data = spark.read.csv(r\"C:\\Users\\asus\\Downloads\\Ecommerce_Customers.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Print schema and sample data\n",
    "data.printSchema()\n",
    "data.show(3)\n",
    "\n",
    "# Assemble features\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=['Avg Session Length', 'Time on App', 'Time on Website', 'Length of Membership'],\n",
    "    outputCol='features'\n",
    ")\n",
    "\n",
    "# Prepare the features and label (target column for regression)\n",
    "output = assembler.transform(data)\n",
    "final_data = output.select('features', 'Yearly Amount Spent')\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_data, test_data = final_data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Initialize Linear Regression model\n",
    "lin_reg = LinearRegression(labelCol='Yearly Amount Spent', featuresCol='features')\n",
    "\n",
    "# Fit the model\n",
    "lin_reg_model = lin_reg.fit(train_data)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "pred_data = lin_reg_model.evaluate(test_data)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Root Mean Squared Error (RMSE):\", pred_data.rootMeanSquaredError)\n",
    "print(\"R-Squared (R2):\", pred_data.r2)\n",
    "\n",
    "# To see predictions\n",
    "pred_data.predictions.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b86610a-c214-4b0d-8372-28594e11ddbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+\n",
      "|            features|Yearly Amount Spent|\n",
      "+--------------------+-------------------+\n",
      "|[34.4972677251122...|  587.9510539684005|\n",
      "|[31.9262720263601...|  392.2049334443264|\n",
      "|[33.0009147556426...| 487.54750486747207|\n",
      "|[34.3055566297555...|  581.8523440352177|\n",
      "|[33.3306725236463...|  599.4060920457634|\n",
      "+--------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6ebe7d-f48a-4ed6-946a-fcf364659644",
   "metadata": {},
   "source": [
    "# logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bb8b230-27f6-43fd-87ad-70b991751cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Email: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- Avatar: string (nullable = true)\n",
      " |-- Avg Session Length: double (nullable = true)\n",
      " |-- Time on App: double (nullable = true)\n",
      " |-- Time on Website: double (nullable = true)\n",
      " |-- Length of Membership: double (nullable = true)\n",
      " |-- Yearly Amount Spent: double (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+---------+------------------+------------------+------------------+--------------------+-------------------+\n",
      "|               Email|             Address|   Avatar|Avg Session Length|       Time on App|   Time on Website|Length of Membership|Yearly Amount Spent|\n",
      "+--------------------+--------------------+---------+------------------+------------------+------------------+--------------------+-------------------+\n",
      "|mstephenson@ferna...|835 Frank TunnelW...|   Violet| 34.49726772511229| 12.65565114916675| 39.57766801952616|  4.0826206329529615|  587.9510539684005|\n",
      "|   hduke@hotmail.com|4547 Archer Commo...|DarkGreen| 31.92627202636016|11.109460728682564|37.268958868297744|    2.66403418213262|  392.2049334443264|\n",
      "|    pallen@yahoo.com|24645 Valerie Uni...|   Bisque|33.000914755642675|11.330278057777512|37.110597442120856|   4.104543202376424| 487.54750486747207|\n",
      "+--------------------+--------------------+---------+------------------+------------------+------------------+--------------------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Accuracy: 0.9652777777777778\n",
      "Precision: [0.96, 0.9710144927536232]\n",
      "Recall: [0.972972972972973, 0.9571428571428572]\n",
      "F1 Score: [0.9664429530201343, 0.9640287769784173]\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|Churn|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|[30.4925366965402...|    1|[-37.573061897343...|[4.81090243793871...|       1.0|\n",
      "|[31.1695067987115...|    1|[-16.129052491715...|[9.89102868956466...|       1.0|\n",
      "|[31.3584771924370...|    1|[-2.5482483534537...|[0.07254425070587...|       1.0|\n",
      "|[31.4474464941278...|    1|[-11.789686067992...|[7.58230245615529...|       1.0|\n",
      "|[31.5147378578019...|    1|[-0.8891542260047...|[0.29128439632763...|       1.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_PYTHON'] = r'C:\\Users\\asus\\anaconda3\\python.exe'\n",
    "os.environ['JAVA_HOME'] = r'C:\\Program Files\\Java\\jdk1.8.0_321'  # Update this to your Java installation path\n",
    "os.environ['SPARK_HOME'] = r'C:\\Users\\asus\\Documents\\BDT\\BigData\\BigData\\spark-3.1.2-bin-hadoop3.2'  # Update this to your Spark installation path\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"Logistic Regression Model\").getOrCreate()\n",
    "\n",
    "# Load the dataset\n",
    "data = spark.read.csv(r\"C:\\Users\\asus\\Downloads\\Ecommerce_Customers.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Print schema and sample data\n",
    "data.printSchema()\n",
    "data.show(3)\n",
    "\n",
    "# Create a binary label column ('Churn') based on 'Yearly Amount Spent'\n",
    "# Assuming: If 'Yearly Amount Spent' < 500, classify as 'Churn' (1), else 'Not Churned' (0)\n",
    "data = data.withColumn(\"Churn\", when(data[\"Yearly Amount Spent\"] < 500, 1).otherwise(0))\n",
    "\n",
    "# Assemble features\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=['Avg Session Length', 'Time on App', 'Time on Website', 'Length of Membership'],\n",
    "    outputCol='features'\n",
    ")\n",
    "\n",
    "# Prepare the features and label (target column for classification)\n",
    "output = assembler.transform(data)\n",
    "final_data = output.select('features', 'Churn')\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_data, test_data = final_data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "log_reg = LogisticRegression(labelCol='Churn', featuresCol='features')\n",
    "\n",
    "# Fit the model\n",
    "log_reg_model = log_reg.fit(train_data)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "pred_data = log_reg_model.evaluate(test_data)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Accuracy:\", pred_data.accuracy)\n",
    "print(\"Precision:\", pred_data.precisionByLabel)\n",
    "print(\"Recall:\", pred_data.recallByLabel)\n",
    "print(\"F1 Score:\", pred_data.fMeasureByLabel())\n",
    "\n",
    "# To see predictions\n",
    "pred_data.predictions.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6b8fc3-3e6b-40c5-aed5-c7adcdb469ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
